from pyspark.sql.types import *
from pyspark.sql.functions import *
import time

from sklearn.preprocessing import OneHotEncoder
start = time.time()
df = spark.createDataFrame([
   ('id_cliente-1',  'cat-1, cat-2, cat-3'),
   ('id_cliente-2',  'cat-1, cat-4, cat-5'),
   ('id_cliente-3',  'cat-6, cat-7'),
   ('id_cliente-4',  'cat-1, cat-2, cat-7, cat-10'),
   ('id_cliente-5',  'cat-8, cat-10'),
   ('id_cliente-6',  'cat-1, cat-9, cat-10'),
   ('id_cliente-7',  'cat-1, cat-4, cat-5, cat-10'),
   ('id_cliente-8',  'cat-7, cat-9'),
   ('id_cliente-9',  'cat-1'),
   ('id_cliente-10', 'cat-1, cat-2, cat-3, cat-4, cat-5, cat-6, cat-7, cat-8, cat-10')
], ['id_cliente', 'categorias'])

df_2=df.select(
      "id_cliente",
      #split("categorias", ", ").alias("cat_2"),
      posexplode(split("categorias", ", ")).alias("pos", "val")
  )#.withColumn("pos", lit(1))

df_3=df_2.select("id_cliente","val").withColumn("pos", lit(1))
df_4=df_3.groupBy("id_cliente").pivot("val").sum("pos")
df_4=df_4.na.fill(0)

print(time.time() - start)
